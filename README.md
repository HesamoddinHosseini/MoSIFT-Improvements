*English:

One of the articles reviewed introduced a model called MoSIFT that tried to identify ongoing activity in videos in a SIFT-inspired manner. The method of identifying features and describing them was derived from SIFT, but changes were made to make the nature of the method more appropriate for the video, taking into account changes over time. In this project, the aim is to increase the accuracy of the MoSIFT method.

 Main Article Link:http://reports-archive.adm.cs.cmu.edu/anon/anon/2009/CMU-CS-09-161.pdf

Chen, M.Y. Hauptmann, A.: MoSIFT: recognizing human actions in surveillance videos (2009)




*Persian:

 یکی از مقالاتی که بررسی شد مدلی را معرفی میکرد به عنوان MoSIFT که با روشی الهام گرفته از SIFT می کوشید فعالیت در حال انجام در ویدیو ها را شناسایی کند. روش شناسایی ویژگی ها و توصیف آنها برگرفته از SIFT بود، اما تغییراتی روی آن اعمال شده بود تا با در نظر گرفتن تغییرات در طول زمان ماهیت روش برای ویدیو مناسب تر شود.
در این پروژه هدف بالا بردن دقت روش MoSIFT است. 

لینک مقاله اصلیhttp://reports-archive.adm.cs.cmu.edu/anon/anon/2009/CMU-CS-09-161.pdf

Chen, M.Y. Hauptmann, A.: MoSIFT: recognizing human actions in surveillance videos (2009)







*How To Run?

A Matlab code is written to recognize human actions namely 'walking', 'jogging','running', 'boxing','hand waving', and 'hand clapping' using Spatio Temporal Interest Points (STIP) and classify the same using a KNN classifier. Please download the KTH Action recognition dataset from the link http://www.nada.kth.se/cvap/actions/ and put them in the folder KTH Dataset folder.
How to run ??
1. Place the 'Action Recognition Code' folder in the Matlab Path, add all the folder and subfolder to the path
2. Run Recognize2.m
3. Select a video from the KTH Dataset
4. Observe results
The code is loosely based on the paper below, please cite and give credit to the authors:

[1] Schüldt, Christian, Ivan Laptev, and Barbara Caputo. "Recognizing human actions: a local SVM approach." Pattern Recognition, 2004. ICPR 2004. Proceedings of the 17th International Conference on. Vol. 3. IEEE, 2004. ftp://ftp.nada.kth.se/CVAP/users/laptev/icpr04actions.pdf

Suggestions and comments are always welcome

Thanks in advance,

H. Hosseini
